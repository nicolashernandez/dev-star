ARTICLE
# -----------------------------------------------------------------------------
des priorités entre dict et regex (spécifique et générales)
dict manque de souplesse mais simple occurrence
regex plus de souplesse mais effet de bord plus difficile à contenir


USAGE
# -----------------------------------------------------------------------------
  java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -i resources/simpleTokenizer/inputText-fr.txt  -r resources/simpleTokenizer/tokens-regex-fr.txt -c "'" 3 -c "’" 3 -c "-" 3 -o wpl -n '.' -n '!' -n '?' --ws-to "_" --preserve-layout -s -v 2>/tmp/log
  java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -i ../data/samples/corpus/fr.text.utf8/JulesVerne.txt  -r resources/simpleTokenizer/tokens-regex-fr.txt -c "'" 3 -c "’" 3 -c "-" 3 -o wst-spl  -n '.' -n '!' -n '?' --ws-to "_" --preserve-layout -s -v 2>/tmp/log
  java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -i ../../teaching/4a.M1.ATAL.Env-Log/environnement-logiciel/data/samples/fr-wikipedia/txt/Affaire_Clearstream_2  -r resources/simpleTokenizer/tokens-regex-fr.txt -c "'" 3 -c "’" 3 -c "-" 3 -o wst-spl  -n '.' -n '!' -n '?' --ws-to "_" --preserve-layout -s -v 2>/tmp/log

cd /home/hernandez/workspace/java-ml-nlp
java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -p resources/simpleTokenizer/simpleTokenizer.fr.properties -i 
#
java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -p resources/simpleTokenizer/simpleTokenizer.fr.wpl.properties -i resources/simpleTokenizer/inputText-fr.txt  |less
java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -p resources/simpleTokenizer/simpleTokenizer.fr.properties -i resources/simpleTokenizer/inputText-fr.txt --single-line-input |less

# test sur les mots composés
java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -p resources/simpleTokenizer/simpleTokenizer.fr.wpl.properties -i /media/MyPassport/workspace/11/111005_constitution-liste-mots-composes-unitexDeLa-web-lefff-melt/resources/delaUnitex-mw-apostrophe.txt 

# word per line
# forme abrégée 
java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -i resources/simpleTokenizer/inputText-fr.txt  -r resources/simpleTokenizer/tokens-regex-fr.txt -c "'" 3 -c "’" 3 -c "-" 3 -o wpl -n '.' -n '!' -n '?' --ws-to "_"  -v 2>/tmp/log | less
#forme étendue
java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine --input-file resources/simpleTokenizer/inputText-fr.txt  --regex-file resources/simpleTokenizer/tokens-regex-fr.txt --codepoint-functioning "'" 3 --codepoint-functioning "’" 3 --codepoint-functioning "-" 3 --output-format wpl --newline-token '.' --newline-token '!' --newline-token '?' --ws-to "_"  -v 2>/tmp/log | less
# avec properties
java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine --properties-file resources/simpleTokenizer/simpleTokenizer.fr.wpl.properties --input-file resources/simpleTokenizer/inputText-fr.txt -v 2>/tmp/log | less

# whitespace separated words + sentence per line
# 
java  -cp bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine --input-file resources/simpleTokenizer/inputText-fr.txt  --regex-file resources/simpleTokenizer/tokens-regex-fr.txt --codepoint-functioning "'" 3 --codepoint-functioning "’" 3 --codepoint-functioning "-" 3 --output-format wst-spl --newline-token '.' --newline-token '!' --newline-token '?' --ws-to "_" --preserve-layout --sweep-output -v 2>/tmp/log | less
# avec properties
JAVAMLNLP_HOME=~/workspace/java-ml-nlp
java  -cp $JAVAMLNLP_HOME/bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -p $JAVAMLNLP_HOME/resources/simpleTokenizer/simpleTokenizer.fr.wst-spl.properties -i $JAVAMLNLP_HOME/resources/simpleTokenizer/exempleText-fr-raw.txt  -v 2>/tmp/log | less
java  -cp $JAVAMLNLP_HOME/bin fr/univnantes/lina/app/tokenizer/RunTokenizerCommandLine -p $JAVAMLNLP_HOME/resources/simpleTokenizer/simpleTokenizer.fr.wst-spl.properties -i $JAVAMLNLP_HOME/resources/simpleTokenizer/exempleText-fr-raw.txt  -v 2>/tmp/log | less

# avec / sans properties pour produire un fichier avec une phrase par ligne

# XP Performance
# -----------------------------------------------------------------------------
i: vs. \Qetc.\E|\QETC.\E| le premier est plus rapide


# XP tokenization WER
# -----------------------------------------------------------------------------

# Auparavant avec 
# ./resources/simpleTokenizer/compute-wer.sh 

# désormais class test
# sous eclipse bouton droit sur la classe test/fr.univnantes.lina.app.tokenizer.TokenizerTest RunAs JunitTest, puis observation de la sortie console
# en lc, 
JAVAMLNLP_HOME=~/workspace/java-ml-nlp
java -cp /usr/share/java/junit4.jar:$JAVAMLNLP_HOME/bin junit.textui.TestRunner fr.univnantes.lina.app.tokenizer.TokenizerTest
# mais ne fonctionne pas (ne trouve pas de test et n'affiche donc pas de sortie std
java -cp /usr/share/java/junit4.jar:$JAVAMLNLP_HOME/bin fr.univnantes.lina.app.tokenizer.TokenizerTest
# ne fonctionne pas non plus... 

DONE
# -----------------------------------------------------------------------------
  + comment spécifier des caractères blancs aux bornes et ne pas les matcher : la notion de groupe sauf que là on a un groupe par ligne et qu'on traite tout comme une seule et même regex... ; effacer les car blancs moi même et modifier l'offset à la mano... : éventuellement un groupe global à l'insu des users et des délimiteurs globaux qui comprennent - mais d'une part perte de souplesse pour les users pour faire au cas par cas et par  ailleurs des formes comme les préclitiques où il n'en faut pas...
finalement des comportements "glue" comme pour les caractères ; non pas exactement on ne veut pas coller à chaque fois aux bornes mais on ne donne pas toujrs la même définition derrière les bornes ; 
quid de l'option une regex indépendante par ligne : une compilation pour toute ; l'exclusivité doit se gérer en annotant pour chaque zone matché les caractères interdits et en vérifiant qu'une zone n'est pas déjà écrite  : lourd...
evaluer preTokenizeText vs preTokenizeText2 : on fait ca pour accéder au groupe pour chaque ligne et avoir ainsi des bornes libres ;
on perd en efficacité au profit de l'expression ; on oblige que toutes les regex on le gorupe 1
  + le default ne doit pas coller quand caractère blanc 
  anniv'_ 120     127
app'_   127     132
  + complete the regex list : voir data/clearstream + ma liste d'abréviation construite voir 111005_constitution-mots-composés-dela-unitex-abrevationWeb
  les ' sont concaténés par défaut (avec \w alphanum, sauf avec ^|\s|$ et punct) 
  les - sont concaténés par défaut 
  //les . sont concaténés par défaut 
  \d{2,} avec une maj
  \w{2,} 
  
  les mots avec - ou ' ou aux extrémités doivent être listés
  si les . sont découpés par défaut, alors tous les mots avec . à ne pas découper doivent aussi être listés 
  + les mots avec - et ' qui contiennent des patrons tokens inférieurs
 + corriger  quelqu'un non considéré en mode wpl
  
TODO
# -----------------------------------------------------------------------------
  + -les avec délimiter \b pose des pb car coupe des mots  Moulinots-les-oies [réf.] , \s et \P{U} même si avec les groupes  on arrive à matcher la zone mange sur le token suivant
  + reprendre le command line createannotation et posttokenization sur le modèle de WordSentenceList pour éviter les erreurs [ref. nécessaire avec un blanc devant " nécessaire" à l'output
  + UIMA AE wrapper extract pretoken pattern compiling in the initialize method
  + eval par rapport à ftb pour savoir comment fonctionne : avec/sans prefix, regex num, clitiq
  + impact sur le training 
  + dict (avec normalisation lowercase)
  + ajuster les regex Nantes-Saint-Nazaire
  + process multilines input and not only as a single line (should be an option, will allow new regex) ; as inputAsSingleLine offer the possibility to use \n in the patterns but may be not relevant for recognising tokens, in opposite, will take occupy less memory ? not sure : to occupy less memory we should revise  the whole process and for each line do what we have to do (pretok, tok and post tok 
  + param global début et fin de chaîne pour tous : non, par défaut chaque ligne de regex list est indépendante  
  + time melt sxpipe 
